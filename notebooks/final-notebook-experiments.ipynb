{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T11:45:05.275150Z",
     "iopub.status.busy": "2024-03-27T11:45:05.274504Z",
     "iopub.status.idle": "2024-03-27T11:45:18.656507Z",
     "shell.execute_reply": "2024-03-27T11:45:18.655510Z",
     "shell.execute_reply.started": "2024-03-27T11:45:05.275125Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops\n",
      "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: einops\n",
      "Successfully installed einops-0.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install einops\n",
    "!git clone https://github.com/b-ptiste/dlmi.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T11:45:18.658391Z",
     "iopub.status.busy": "2024-03-27T11:45:18.658022Z",
     "iopub.status.idle": "2024-03-27T11:45:34.631736Z",
     "shell.execute_reply": "2024-03-27T11:45:34.630676Z",
     "shell.execute_reply.started": "2024-03-27T11:45:18.658340Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'dlmi'...\n",
      "remote: Enumerating objects: 215, done.\u001b[K\n",
      "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
      "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
      "remote: Total 215 (delta 0), reused 3 (delta 0), pack-reused 210\u001b[K\n",
      "Receiving objects: 100% (215/215), 39.75 KiB | 3.97 MiB/s, done.\n",
      "Resolving deltas: 100% (80/80), done.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "\n",
    "# Related third-party imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms as T\n",
    "from torchvision.transforms import v2\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "import wandb\n",
    "import uuid\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# log in different framework\n",
    "path_root = \"/kaggle/input/dlmi-challenge-b-and-s\"\n",
    "path_working = \"/kaggle/working\"\n",
    "path_mae = \"/kaggle/input/pretrain-mae\"\n",
    "\n",
    "\n",
    "# local library\n",
    "from dlmi.src.model import ModelFactory\n",
    "from dlmi.src.data import csv_processing, DataloaderFactory\n",
    "from dlmi.src.utils import get_stratified_split\n",
    "from dlmi.src.mae_pretraining import MAE_ViT, MAE_Encoder, MAE_Decoder, PatchShuffle\n",
    "from dlmi.data.split import train_index as train_index_strat\n",
    "from dlmi.data.split import val_index as val_index_strat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data importation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Csv import with pre-processing, reformatting and normalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T11:45:34.634227Z",
     "iopub.status.busy": "2024-03-27T11:45:34.633413Z",
     "iopub.status.idle": "2024-03-27T11:45:34.681956Z",
     "shell.execute_reply": "2024-03-27T11:45:34.681053Z",
     "shell.execute_reply.started": "2024-03-27T11:45:34.634186Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_annotation_train = csv_processing(\n",
    "    os.path.join(path_root, \"trainset\", \"trainset_true.csv\")\n",
    ")\n",
    "df_annotation_test = csv_processing(\n",
    "    os.path.join(path_root, \"testset\", \"testset_data.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train, val, test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T11:45:34.684884Z",
     "iopub.status.busy": "2024-03-27T11:45:34.684589Z",
     "iopub.status.idle": "2024-03-27T11:45:34.689356Z",
     "shell.execute_reply": "2024-03-27T11:45:34.688292Z",
     "shell.execute_reply.started": "2024-03-27T11:45:34.684860Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mode_split = \"strat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T11:45:34.690835Z",
     "iopub.status.busy": "2024-03-27T11:45:34.690536Z",
     "iopub.status.idle": "2024-03-27T11:45:34.703187Z",
     "shell.execute_reply": "2024-03-27T11:45:34.702330Z",
     "shell.execute_reply.started": "2024-03-27T11:45:34.690811Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_index = df_annotation_test.index.tolist()\n",
    "\n",
    "if mode_split == \"auto\":\n",
    "    map_mode_index = get_stratified_split(df_annotation_train, df_annotation_test)\n",
    "\n",
    "    train_index = map_mode_index[\"train\"]\n",
    "    val_index = map_mode_index[\"val\"]\n",
    "\n",
    "elif mode_split == \"load\":\n",
    "    # log wandb\n",
    "    run = wandb.init()\n",
    "    artifact = run.use_artifact(\n",
    "        \"ii_timm/DLMI/submission958f5028e70811ee9d6b0242ac130202:v0\", type=\"csv\"\n",
    "    )\n",
    "    artifact_dir = artifact.download(root=path_working)\n",
    "    wandb.finish()\n",
    "\n",
    "    train_index = pd.read_csv(f\"{path_working}/train_index.csv\")[\n",
    "        \"train\"\n",
    "    ].values.tolist()\n",
    "    val_index = pd.read_csv(f\"{path_working}/val_index.csv\")[\"val\"].values.tolist()\n",
    "\n",
    "elif mode_split == \"strat\":\n",
    "    test_index = df_annotation_test.index.tolist()\n",
    "\n",
    "if mode_split == \"auto\":\n",
    "    map_mode_index = get_stratified_split(df_annotation_train, df_annotation_test)\n",
    "\n",
    "    train_index = map_mode_index[\"train\"]\n",
    "    val_index = map_mode_index[\"val\"]\n",
    "\n",
    "elif mode_split == \"load\":\n",
    "    # log wandb\n",
    "    run = wandb.init()\n",
    "    artifact = run.use_artifact(\n",
    "        \"ii_timm/DLMI/submission958f5028e70811ee9d6b0242ac130202:v0\", type=\"csv\"\n",
    "    )\n",
    "    artifact_dir = artifact.download(root=path_working)\n",
    "    wandb.finish()\n",
    "\n",
    "    train_index = pd.read_csv(f\"{path_working}/train_index.csv\")[\n",
    "        \"train\"\n",
    "    ].values.tolist()\n",
    "    val_index = pd.read_csv(f\"{path_working}/val_index.csv\")[\"val\"].values.tolist()\n",
    "\n",
    "elif mode_split == \"strat\":\n",
    "    train_index = train_index_strat\n",
    "    val_index = val_index_strat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T11:45:34.704822Z",
     "iopub.status.busy": "2024-03-27T11:45:34.704487Z",
     "iopub.status.idle": "2024-03-27T11:45:35.181765Z",
     "shell.execute_reply": "2024-03-27T11:45:35.180899Z",
     "shell.execute_reply.started": "2024-03-27T11:45:34.704793Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T11:45:35.184143Z",
     "iopub.status.busy": "2024-03-27T11:45:35.182962Z",
     "iopub.status.idle": "2024-03-27T11:45:35.198111Z",
     "shell.execute_reply": "2024-03-27T11:45:35.197032Z",
     "shell.execute_reply.started": "2024-03-27T11:45:35.184106Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train_clf = df_annotation_train.loc[train_index]\n",
    "df_val_clf = df_annotation_train.loc[val_index]\n",
    "\n",
    "y_train = df_train_clf[\"LABEL\"]\n",
    "y_val = df_val_clf[\"LABEL\"]\n",
    "df_train_clf = df_train_clf.drop(columns=[\"GENDER\", \"DOB\", \"LABEL\", \"ID\"])\n",
    "df_val_clf = df_val_clf.drop(columns=[\"GENDER\", \"DOB\", \"LABEL\", \"ID\"])\n",
    "df_train_clf[\"BIN_GENDER\"] = df_train_clf[\"BIN_GENDER\"].astype(int)\n",
    "df_val_clf[\"BIN_GENDER\"] = df_val_clf[\"BIN_GENDER\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T11:45:35.199548Z",
     "iopub.status.busy": "2024-03-27T11:45:35.199225Z",
     "iopub.status.idle": "2024-03-27T11:45:35.212043Z",
     "shell.execute_reply": "2024-03-27T11:45:35.211246Z",
     "shell.execute_reply.started": "2024-03-27T11:45:35.199523Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 2, 10)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 1, 10)\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
    "    return cross_val_score(\n",
    "        clf,\n",
    "        df_train_clf.values,\n",
    "        y_train,\n",
    "        n_jobs=-1,\n",
    "        cv=5,\n",
    "        scoring=make_scorer(balanced_accuracy_score),\n",
    "    ).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T11:45:35.213648Z",
     "iopub.status.busy": "2024-03-27T11:45:35.213179Z",
     "iopub.status.idle": "2024-03-27T11:45:35.230525Z",
     "shell.execute_reply": "2024-03-27T11:45:35.229674Z",
     "shell.execute_reply.started": "2024-03-27T11:45:35.213618Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=1999)\n",
    "df_train_clf, y_train = smote.fit_resample(df_train_clf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T11:45:35.232706Z",
     "iopub.status.busy": "2024-03-27T11:45:35.231970Z",
     "iopub.status.idle": "2024-03-27T11:45:43.951673Z",
     "shell.execute_reply": "2024-03-27T11:45:43.950676Z",
     "shell.execute_reply.started": "2024-03-27T11:45:35.232656Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 11:45:35,234] A new study created in memory with name: no-name-7127d3b0-c30d-44c4-94ab-4a0846e38848\n",
      "[I 2024-03-27 11:45:37,112] Trial 0 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 7, 'max_depth': 2}. Best is trial 0 with value: 0.8388888888888889.\n",
      "[I 2024-03-27 11:45:37,152] Trial 1 finished with value: 0.8444444444444444 and parameters: {'n_estimators': 4, 'max_depth': 5}. Best is trial 1 with value: 0.8444444444444444.\n",
      "[I 2024-03-27 11:45:37,188] Trial 2 finished with value: 0.8333333333333333 and parameters: {'n_estimators': 3, 'max_depth': 3}. Best is trial 1 with value: 0.8444444444444444.\n",
      "[I 2024-03-27 11:45:37,224] Trial 3 finished with value: 0.861111111111111 and parameters: {'n_estimators': 4, 'max_depth': 5}. Best is trial 3 with value: 0.861111111111111.\n",
      "[I 2024-03-27 11:45:37,260] Trial 4 finished with value: 0.861111111111111 and parameters: {'n_estimators': 3, 'max_depth': 6}. Best is trial 3 with value: 0.861111111111111.\n",
      "[I 2024-03-27 11:45:37,316] Trial 5 finished with value: 0.888888888888889 and parameters: {'n_estimators': 6, 'max_depth': 10}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:37,388] Trial 6 finished with value: 0.8666666666666666 and parameters: {'n_estimators': 8, 'max_depth': 8}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:37,435] Trial 7 finished with value: 0.8444444444444444 and parameters: {'n_estimators': 4, 'max_depth': 9}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:37,489] Trial 8 finished with value: 0.8722222222222221 and parameters: {'n_estimators': 5, 'max_depth': 7}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:37,568] Trial 9 finished with value: 0.8111111111111111 and parameters: {'n_estimators': 10, 'max_depth': 3}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:37,653] Trial 10 finished with value: 0.8444444444444444 and parameters: {'n_estimators': 9, 'max_depth': 10}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:37,725] Trial 11 finished with value: 0.8555555555555554 and parameters: {'n_estimators': 6, 'max_depth': 7}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:37,806] Trial 12 finished with value: 0.8666666666666666 and parameters: {'n_estimators': 6, 'max_depth': 10}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:37,866] Trial 13 finished with value: 0.861111111111111 and parameters: {'n_estimators': 5, 'max_depth': 8}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:37,908] Trial 14 finished with value: 0.8444444444444444 and parameters: {'n_estimators': 2, 'max_depth': 7}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:37,970] Trial 15 finished with value: 0.888888888888889 and parameters: {'n_estimators': 6, 'max_depth': 9}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:38,043] Trial 16 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 7, 'max_depth': 10}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:38,126] Trial 17 finished with value: 0.8555555555555555 and parameters: {'n_estimators': 8, 'max_depth': 9}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:38,200] Trial 18 finished with value: 0.8555555555555555 and parameters: {'n_estimators': 7, 'max_depth': 9}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:38,261] Trial 19 finished with value: 0.8555555555555555 and parameters: {'n_estimators': 5, 'max_depth': 8}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:38,324] Trial 20 finished with value: 0.7555555555555555 and parameters: {'n_estimators': 6, 'max_depth': 1}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:38,387] Trial 21 finished with value: 0.8277777777777778 and parameters: {'n_estimators': 5, 'max_depth': 7}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:38,461] Trial 22 finished with value: 0.8666666666666666 and parameters: {'n_estimators': 5, 'max_depth': 6}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:38,534] Trial 23 finished with value: 0.8222222222222222 and parameters: {'n_estimators': 6, 'max_depth': 9}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:38,618] Trial 24 finished with value: 0.85 and parameters: {'n_estimators': 8, 'max_depth': 8}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:38,692] Trial 25 finished with value: 0.8777777777777777 and parameters: {'n_estimators': 7, 'max_depth': 10}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:38,766] Trial 26 finished with value: 0.861111111111111 and parameters: {'n_estimators': 7, 'max_depth': 10}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:38,866] Trial 27 finished with value: 0.8333333333333333 and parameters: {'n_estimators': 9, 'max_depth': 10}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:38,936] Trial 28 finished with value: 0.8833333333333334 and parameters: {'n_estimators': 6, 'max_depth': 9}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:39,010] Trial 29 finished with value: 0.85 and parameters: {'n_estimators': 6, 'max_depth': 9}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:39,085] Trial 30 finished with value: 0.8777777777777777 and parameters: {'n_estimators': 7, 'max_depth': 4}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:39,159] Trial 31 finished with value: 0.8444444444444444 and parameters: {'n_estimators': 7, 'max_depth': 9}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:39,243] Trial 32 finished with value: 0.8555555555555555 and parameters: {'n_estimators': 8, 'max_depth': 10}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:39,319] Trial 33 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 7, 'max_depth': 8}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:39,383] Trial 34 finished with value: 0.861111111111111 and parameters: {'n_estimators': 6, 'max_depth': 9}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:39,435] Trial 35 finished with value: 0.8277777777777778 and parameters: {'n_estimators': 4, 'max_depth': 10}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:39,497] Trial 36 finished with value: 0.8666666666666666 and parameters: {'n_estimators': 5, 'max_depth': 8}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:39,559] Trial 37 finished with value: 0.8277777777777778 and parameters: {'n_estimators': 6, 'max_depth': 5}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:39,620] Trial 38 finished with value: 0.861111111111111 and parameters: {'n_estimators': 4, 'max_depth': 6}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:39,704] Trial 39 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 8, 'max_depth': 9}. Best is trial 5 with value: 0.888888888888889.\n",
      "[I 2024-03-27 11:45:39,787] Trial 40 finished with value: 0.9 and parameters: {'n_estimators': 9, 'max_depth': 10}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:39,870] Trial 41 finished with value: 0.85 and parameters: {'n_estimators': 9, 'max_depth': 10}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:39,955] Trial 42 finished with value: 0.8555555555555555 and parameters: {'n_estimators': 10, 'max_depth': 9}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:40,038] Trial 43 finished with value: 0.85 and parameters: {'n_estimators': 9, 'max_depth': 10}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:40,122] Trial 44 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 10, 'max_depth': 10}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:40,185] Trial 45 finished with value: 0.8555555555555555 and parameters: {'n_estimators': 6, 'max_depth': 9}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:40,238] Trial 46 finished with value: 0.8111111111111111 and parameters: {'n_estimators': 3, 'max_depth': 3}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:40,311] Trial 47 finished with value: 0.8666666666666668 and parameters: {'n_estimators': 7, 'max_depth': 8}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:40,375] Trial 48 finished with value: 0.861111111111111 and parameters: {'n_estimators': 5, 'max_depth': 10}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:40,449] Trial 49 finished with value: 0.8555555555555555 and parameters: {'n_estimators': 8, 'max_depth': 7}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:40,513] Trial 50 finished with value: 0.861111111111111 and parameters: {'n_estimators': 6, 'max_depth': 9}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:40,586] Trial 51 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 7, 'max_depth': 3}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:40,660] Trial 52 finished with value: 0.8333333333333333 and parameters: {'n_estimators': 7, 'max_depth': 2}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:40,724] Trial 53 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 6, 'max_depth': 4}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:40,799] Trial 54 finished with value: 0.8555555555555555 and parameters: {'n_estimators': 7, 'max_depth': 4}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:40,873] Trial 55 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 6, 'max_depth': 4}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:40,950] Trial 56 finished with value: 0.8666666666666666 and parameters: {'n_estimators': 8, 'max_depth': 10}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:41,035] Trial 57 finished with value: 0.85 and parameters: {'n_estimators': 9, 'max_depth': 6}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:41,100] Trial 58 finished with value: 0.861111111111111 and parameters: {'n_estimators': 5, 'max_depth': 4}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:41,175] Trial 59 finished with value: 0.8777777777777779 and parameters: {'n_estimators': 7, 'max_depth': 5}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:41,250] Trial 60 finished with value: 0.861111111111111 and parameters: {'n_estimators': 8, 'max_depth': 5}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:41,325] Trial 61 finished with value: 0.8722222222222221 and parameters: {'n_estimators': 7, 'max_depth': 5}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:41,390] Trial 62 finished with value: 0.8722222222222221 and parameters: {'n_estimators': 6, 'max_depth': 5}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:41,465] Trial 63 finished with value: 0.8333333333333333 and parameters: {'n_estimators': 7, 'max_depth': 2}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:41,529] Trial 64 finished with value: 0.8333333333333333 and parameters: {'n_estimators': 5, 'max_depth': 9}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:41,604] Trial 65 finished with value: 0.8555555555555555 and parameters: {'n_estimators': 7, 'max_depth': 4}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:41,669] Trial 66 finished with value: 0.85 and parameters: {'n_estimators': 6, 'max_depth': 10}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:41,744] Trial 67 finished with value: 0.8277777777777778 and parameters: {'n_estimators': 7, 'max_depth': 10}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:41,830] Trial 68 finished with value: 0.8722222222222221 and parameters: {'n_estimators': 8, 'max_depth': 7}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:41,896] Trial 69 finished with value: 0.8277777777777778 and parameters: {'n_estimators': 5, 'max_depth': 9}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:41,972] Trial 70 finished with value: 0.8555555555555555 and parameters: {'n_estimators': 6, 'max_depth': 8}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:42,038] Trial 71 finished with value: 0.8666666666666666 and parameters: {'n_estimators': 4, 'max_depth': 9}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:42,104] Trial 72 finished with value: 0.8222222222222222 and parameters: {'n_estimators': 5, 'max_depth': 10}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:42,160] Trial 73 finished with value: 0.8666666666666666 and parameters: {'n_estimators': 3, 'max_depth': 6}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:42,225] Trial 74 finished with value: 0.8222222222222222 and parameters: {'n_estimators': 6, 'max_depth': 8}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:42,291] Trial 75 finished with value: 0.8555555555555557 and parameters: {'n_estimators': 5, 'max_depth': 10}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:42,356] Trial 76 finished with value: 0.85 and parameters: {'n_estimators': 6, 'max_depth': 5}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:42,428] Trial 77 finished with value: 0.8277777777777778 and parameters: {'n_estimators': 6, 'max_depth': 7}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:42,505] Trial 78 finished with value: 0.8777777777777779 and parameters: {'n_estimators': 7, 'max_depth': 9}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:42,583] Trial 79 finished with value: 0.85 and parameters: {'n_estimators': 7, 'max_depth': 9}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:42,680] Trial 80 finished with value: 0.85 and parameters: {'n_estimators': 10, 'max_depth': 9}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:42,756] Trial 81 finished with value: 0.8277777777777778 and parameters: {'n_estimators': 7, 'max_depth': 10}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:42,843] Trial 82 finished with value: 0.8555555555555555 and parameters: {'n_estimators': 8, 'max_depth': 8}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:42,920] Trial 83 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 7, 'max_depth': 9}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:42,998] Trial 84 finished with value: 0.8555555555555555 and parameters: {'n_estimators': 6, 'max_depth': 10}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:43,056] Trial 85 finished with value: 0.8277777777777778 and parameters: {'n_estimators': 2, 'max_depth': 7}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:43,134] Trial 86 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 6, 'max_depth': 9}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:43,190] Trial 87 finished with value: 0.8777777777777779 and parameters: {'n_estimators': 4, 'max_depth': 10}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:43,256] Trial 88 finished with value: 0.85 and parameters: {'n_estimators': 4, 'max_depth': 10}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:43,304] Trial 89 finished with value: 0.8388888888888888 and parameters: {'n_estimators': 2, 'max_depth': 3}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:43,391] Trial 90 finished with value: 0.861111111111111 and parameters: {'n_estimators': 9, 'max_depth': 10}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:43,449] Trial 91 finished with value: 0.888888888888889 and parameters: {'n_estimators': 4, 'max_depth': 10}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:43,507] Trial 92 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 3, 'max_depth': 10}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:43,574] Trial 93 finished with value: 0.8777777777777779 and parameters: {'n_estimators': 4, 'max_depth': 10}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:43,642] Trial 94 finished with value: 0.8444444444444444 and parameters: {'n_estimators': 4, 'max_depth': 10}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:43,711] Trial 95 finished with value: 0.8444444444444443 and parameters: {'n_estimators': 4, 'max_depth': 10}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:43,772] Trial 96 finished with value: 0.8555555555555555 and parameters: {'n_estimators': 4, 'max_depth': 9}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:43,830] Trial 97 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 3, 'max_depth': 10}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:43,889] Trial 98 finished with value: 0.861111111111111 and parameters: {'n_estimators': 4, 'max_depth': 10}. Best is trial 40 with value: 0.9.\n",
      "[I 2024-03-27 11:45:43,946] Trial 99 finished with value: 0.85 and parameters: {'n_estimators': 3, 'max_depth': 9}. Best is trial 40 with value: 0.9.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy: 0.9\n",
      "Best hyperparameters: {'n_estimators': 9, 'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "trial = study.best_trial\n",
    "print(\"Balanced accuracy: {}\".format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T11:45:43.953352Z",
     "iopub.status.busy": "2024-03-27T11:45:43.953081Z",
     "iopub.status.idle": "2024-03-27T11:45:43.985771Z",
     "shell.execute_reply": "2024-03-27T11:45:43.984888Z",
     "shell.execute_reply.started": "2024-03-27T11:45:43.953326Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "# Extract the best hyperparameters\n",
    "best_params = study.best_trial.params\n",
    "\n",
    "# Create the XGBoost classifier with the best hyperparameters\n",
    "best_clf = RandomForestClassifier(**best_params)\n",
    "\n",
    "# Train the classifier on the full training dataset\n",
    "best_clf.fit(df_train_clf.values, y_train)\n",
    "\n",
    "\n",
    "y_pred = best_clf.predict(df_val_clf.values)\n",
    "\n",
    "# Evaluate the model\n",
    "print(balanced_accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Finetuning¶:\n",
    "\n",
    "The following models are supported but basically all VIT, ResNet and EfficientNet from Timm are supported !\n",
    "\n",
    "FROM : https://github.com/huggingface/pytorch-image-models/blob/main/timm/models/vision_transformer.py\n",
    "\n",
    "    vit_tiny_patch16_224.augreg_in21k_ft_in1k\n",
    "    vit_tiny_patch16_224.augreg_in21k\n",
    "    vit_small_patch32_224.augreg_in21k\n",
    "    vit_small_patch16_224.augreg_in21k (actual)\n",
    "\n",
    "DINO\n",
    "\n",
    "    vit_small_patch16_224.dino\n",
    "    vit_small_patch8_224.dino\n",
    "\n",
    "DINOv2\n",
    "\n",
    "    vit_small_patch14_dinov2.lvd142m\n",
    "    vit_small_patch14_reg4_dinov2.lvd142m\n",
    "\n",
    "FlexiVit\n",
    "\n",
    "    flexivit_small.300ep_in1k\n",
    "    flexivit_small.1200ep_in1k\n",
    "\n",
    "OpenAI\n",
    "\n",
    "    vit_xsmall_patch16_clip_224.tinyclip_yfcc15m\n",
    "\n",
    "Resnet\n",
    "\n",
    "EfficientNet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T11:45:43.987326Z",
     "iopub.status.busy": "2024-03-27T11:45:43.986976Z",
     "iopub.status.idle": "2024-03-27T11:45:43.996572Z",
     "shell.execute_reply": "2024-03-27T11:45:43.995756Z",
     "shell.execute_reply.started": "2024-03-27T11:45:43.987295Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"who\": \"baptiste\",  # or steven\n",
    "    \"no_wandb\": True,\n",
    "    \"name_exp\": \"PatientModelAttentionTab - vit_tiny_patch16_224 - bottleneck\",\n",
    "    \"lr\": 1e-5,\n",
    "    \"batch_size\": 124,\n",
    "    \"nb_epochs\": 10,\n",
    "    \"timm\": True,  # is the model from timm\n",
    "    \"timm_model\": \"vit_small_patch16_224.augreg_in21k\",\n",
    "    \"dino\": False,\n",
    "    \"dino_size\": \"\",  # vits, vitb, vitl, vitg\n",
    "    \"adapter\": \"\",  # bottleneck, adaptformer, lora, prompttuning\n",
    "    \"model_name\": \"\",  #\n",
    "    \"pretrained\": True,\n",
    "    \"pretrained_path\": \"\",\n",
    "    \"nb_class\": 2,\n",
    "    \"scheduler\": None,  # could be empty or linear, expo ...\n",
    "    \"dataset_name\": \"DatasetPerImg\",\n",
    "    \"device_1\": \"cuda:0\",\n",
    "    \"device_2\": \"cuda:1\",  # for double device\n",
    "    # data augmentation\n",
    "    \"filename\": f\"{path_working}/submission_pretrain.csv\",\n",
    "    \"filename_finetune\": f\"{path_working}/submission_finetune.csv\",\n",
    "    \"sub_batch_size\": 16,\n",
    "    \"latent_att\": 512,\n",
    "    \"head_1\": 8,  # 4\n",
    "    \"head_2\": 2,\n",
    "    \"feature_dim\": 384,  # DINOv2, VIT: 192 - 384\n",
    "    \"aggregation\": \"sum\",  # sum, avg, max\n",
    "    \"beta_1\": 0.5,\n",
    "    \"beta_2\": 0.9,\n",
    "    \"weight_decay\": 5e-2,\n",
    "    \"weight_class_0\": 3.0,\n",
    "    \"weight_class_1\": 1.0,\n",
    "    \"mask_ratio\": 0.75,\n",
    "    \"image_size\": 224,\n",
    "    \"patch_size\": 16,\n",
    "    \"mae_pretrained\": \"\",\n",
    "    \"with_tab\": True,\n",
    "    \"mode_split\": \"strat\",  # load, strat\n",
    "    \"degrees\": (-5, 5),\n",
    "    \"translate\": (0.1, 0.1),\n",
    "    \"scale\": (1.0, 1.1),\n",
    "    \"fill\": (255, 232, 201),\n",
    "    \"p\": 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T11:45:44.000705Z",
     "iopub.status.busy": "2024-03-27T11:45:44.000450Z",
     "iopub.status.idle": "2024-03-27T11:45:44.011924Z",
     "shell.execute_reply": "2024-03-27T11:45:44.010852Z",
     "shell.execute_reply.started": "2024-03-27T11:45:44.000684Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# transform\n",
    "transform_train = T.Compose(\n",
    "    [\n",
    "        v2.PILToTensor(),\n",
    "        v2.RandomHorizontalFlip(p=cfg[\"p\"]),\n",
    "        v2.RandomVerticalFlip(p=cfg[\"p\"]),\n",
    "        v2.RandomAffine(\n",
    "            degrees=cfg[\"degrees\"],\n",
    "            translate=cfg[\"translate\"],\n",
    "            scale=cfg[\"scale\"],\n",
    "            fill=cfg[\"fill\"],\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_val = T.Compose(\n",
    "    [\n",
    "        v2.PILToTensor(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T11:45:44.013221Z",
     "iopub.status.busy": "2024-03-27T11:45:44.012984Z",
     "iopub.status.idle": "2024-03-27T11:45:49.289252Z",
     "shell.execute_reply": "2024-03-27T11:45:49.288334Z",
     "shell.execute_reply.started": "2024-03-27T11:45:44.013201Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The configuration is:\n",
      "who : baptiste\n",
      "no_wandb : True\n",
      "name_exp : PatientModelAttentionTab - vit_tiny_patch16_224 - bottleneck\n",
      "lr : 1e-05\n",
      "batch_size : 124\n",
      "nb_epochs : 10\n",
      "timm : True\n",
      "timm_model : vit_small_patch16_224.augreg_in21k\n",
      "dino : False\n",
      "dino_size : \n",
      "adapter : \n",
      "model_name : \n",
      "pretrained : True\n",
      "pretrained_path : \n",
      "nb_class : 2\n",
      "scheduler : None\n",
      "dataset_name : DatasetPerImg\n",
      "device_1 : cuda:0\n",
      "device_2 : cuda:1\n",
      "filename : /kaggle/working/submission_pretrain.csv\n",
      "filename_finetune : /kaggle/working/submission_finetune.csv\n",
      "sub_batch_size : 16\n",
      "latent_att : 512\n",
      "head_1 : 8\n",
      "head_2 : 2\n",
      "feature_dim : 384\n",
      "aggregation : sum\n",
      "beta_1 : 0.5\n",
      "beta_2 : 0.9\n",
      "weight_decay : 0.05\n",
      "weight_class_0 : 3.0\n",
      "weight_class_1 : 1.0\n",
      "mask_ratio : 0.75\n",
      "image_size : 224\n",
      "patch_size : 16\n",
      "mae_pretrained : \n",
      "with_tab : True\n",
      "mode_split : strat\n",
      "degrees : (-5, 5)\n",
      "translate : (0.1, 0.1)\n",
      "scale : (1.0, 1.1)\n",
      "fill : (255, 232, 201)\n",
      "p : 0.1\n",
      "Loading timm model vit_small_patch16_224.augreg_in21k\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1636e7439bf1437fbc8821a82ac4232e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/120M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No adapter used\n",
      "==================================================\n",
      "The model has 21666434 parameters\n",
      "The model has 21666434 trainable parameters\n",
      "It represents 100.0 % trainable parameters\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data_factory = DataloaderFactory()\n",
    "model_factory = ModelFactory()\n",
    "dataloader_train = data_factory(\n",
    "    cfg,\n",
    "    mode=\"train\",\n",
    "    split_indexes=train_index,\n",
    "    path_root=path_root,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    transform=transform_train,\n",
    "    oversampling={\"0\": 1, \"1\": 1},\n",
    ")\n",
    "\n",
    "dataloader_val = data_factory(\n",
    "    cfg,\n",
    "    mode=\"train\",\n",
    "    split_indexes=val_index,\n",
    "    path_root=path_root,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    transform=transform_val,\n",
    "    oversampling={\"0\": 1, \"1\": 1},\n",
    ")\n",
    "\n",
    "\n",
    "# load model\n",
    "model = model_factory(cfg).to(cfg[\"device_1\"])\n",
    "\n",
    "# optimizer and scheduler\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=cfg[\"lr\"],\n",
    "    betas=(cfg[\"beta_1\"], cfg[\"beta_2\"]),\n",
    "    weight_decay=cfg[\"weight_decay\"],\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=cfg[\"nb_epochs\"], eta_min=5e-6\n",
    ")\n",
    "# weight = torch.tensor([cfg['weight_class_0'], cfg['weight_class_1']]).to(cfg['device_1'])\n",
    "# loss_fn = torch.nn.CrossEntropyLoss(weight=weight)\n",
    "\n",
    "soft_max = torch.nn.Softmax(1)\n",
    "\n",
    "\n",
    "cfg[\"nb_params_train\"] = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "cfg[\"nb_params_tot\"] = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f'The model has {cfg[\"nb_params_tot\"]} parameters')\n",
    "print(f'The model has {cfg[\"nb_params_train\"]} trainable parameters')\n",
    "print(\n",
    "    f'It represents {np.round(100 * cfg[\"nb_params_train\"]/cfg[\"nb_params_tot\"], 3)} % trainable parameters'\n",
    ")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T11:45:49.290657Z",
     "iopub.status.busy": "2024-03-27T11:45:49.290361Z",
     "iopub.status.idle": "2024-03-27T11:45:49.295486Z",
     "shell.execute_reply": "2024-03-27T11:45:49.294617Z",
     "shell.execute_reply.started": "2024-03-27T11:45:49.290633Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "weight = torch.tensor([2.5, 1.0]).to(\"cuda:0\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T11:45:49.296963Z",
     "iopub.status.busy": "2024-03-27T11:45:49.296674Z",
     "iopub.status.idle": "2024-03-27T12:00:58.389655Z",
     "shell.execute_reply": "2024-03-27T12:00:58.388696Z",
     "shell.execute_reply.started": "2024-03-27T11:45:49.296928Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training ...\n",
      "==================================================\n",
      "                Epoch 0\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [01:58<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.691915 / train_avg_loss : 0.500355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:24<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.71803 / val_avg_loss : 0.382228\n",
      "Improve avg accuracy :\n",
      "checkpoint saved to: ./model0.pt\n",
      "==================================================\n",
      "                Epoch 1\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [01:13<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.757054 / train_avg_loss : 0.400541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:12<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.734628 / val_avg_loss : 0.365978\n",
      "Improve avg accuracy :\n",
      "checkpoint saved to: ./model1.pt\n",
      "==================================================\n",
      "                Epoch 2\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [01:13<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.767836 / train_avg_loss : 0.36455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:12<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.742147 / val_avg_loss : 0.3634\n",
      "Improve avg accuracy :\n",
      "checkpoint saved to: ./model2.pt\n",
      "==================================================\n",
      "                Epoch 3\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [01:12<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.794636 / train_avg_loss : 0.321676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:12<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.746394 / val_avg_loss : 0.347904\n",
      "Improve avg accuracy :\n",
      "checkpoint saved to: ./model3.pt\n",
      "==================================================\n",
      "                Epoch 4\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [01:11<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.80644 / train_avg_loss : 0.298472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:12<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.752315 / val_avg_loss : 0.316258\n",
      "Improve avg accuracy :\n",
      "checkpoint saved to: ./model4.pt\n",
      "==================================================\n",
      "                Epoch 5\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [01:12<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.823498 / train_avg_loss : 0.271789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:12<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.733394 / val_avg_loss : 0.354955\n",
      "==================================================\n",
      "                Epoch 6\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [01:10<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.832131 / train_avg_loss : 0.254222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:12<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.728699 / val_avg_loss : 0.368378\n",
      "==================================================\n",
      "                Epoch 7\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [01:11<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.846562 / train_avg_loss : 0.233343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:12<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.724887 / val_avg_loss : 0.358291\n",
      "==================================================\n",
      "                Epoch 8\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [01:12<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.858562 / train_avg_loss : 0.211241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:12<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.738544 / val_avg_loss : 0.340689\n",
      "==================================================\n",
      "                Epoch 9\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [01:11<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.860986 / train_avg_loss : 0.205668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:12<00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.738439 / val_avg_loss : 0.348372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = -1\n",
    "\n",
    "if not cfg[\"no_wandb\"]:\n",
    "    run = wandb.init(\n",
    "        project=\"DLMI\",\n",
    "        entity=\"ii_timm\",\n",
    "        name=cfg[\"name_exp\"],\n",
    "        config=cfg,\n",
    "    )\n",
    "\n",
    "print(\"Start Training ...\")\n",
    "\n",
    "for epoch in range(cfg[\"nb_epochs\"]):\n",
    "    model.train()\n",
    "    print(\"=\" * 50)\n",
    "    print(\" \" * 15, f\"Epoch {epoch}\")\n",
    "    print(\"=\" * 50)\n",
    "    train_pred = []\n",
    "    train_label = []\n",
    "    tain_cum_loss = 0\n",
    "    for x, annotation in tqdm(dataloader_train):\n",
    "        # reset gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        x = x.to(cfg[\"device_1\"])\n",
    "        x = model(x)\n",
    "\n",
    "        # compute loss\n",
    "        loss = loss_fn(x, annotation[\"LABEL\"].to(cfg[\"device_1\"]))\n",
    "        pred = torch.argmax(soft_max(x), dim=1)\n",
    "        tain_cum_loss += loss.item()\n",
    "\n",
    "        train_pred.extend(pred.detach().cpu().tolist())\n",
    "        train_label.extend(annotation[\"LABEL\"].detach().cpu().tolist())\n",
    "\n",
    "        # gradient decent\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "    train_balance_acc = balanced_accuracy_score(train_pred, train_label)\n",
    "    train_avg_loss = tain_cum_loss / len(dataloader_train)\n",
    "    print(\n",
    "        f\"train_balance_acc : {np.round(train_balance_acc, 6)} / train_avg_loss : {np.round(train_avg_loss, 6)}\"\n",
    "    )\n",
    "\n",
    "    val_pred = []\n",
    "    val_label = []\n",
    "    val_cum_loss = 0\n",
    "    model.eval()\n",
    "    for x, annotation in tqdm(dataloader_val):\n",
    "        # forward\n",
    "        x = x.to(cfg[\"device_1\"])\n",
    "        with torch.no_grad():\n",
    "            x = model(x)\n",
    "\n",
    "        # compute loss\n",
    "        loss = loss_fn(x, annotation[\"LABEL\"].to(cfg[\"device_1\"]))\n",
    "        pred = torch.argmax(soft_max(x), dim=1)\n",
    "        val_cum_loss += loss.item()\n",
    "        val_pred.extend(pred.detach().cpu().tolist())\n",
    "        val_label.extend(annotation[\"LABEL\"].detach().cpu().tolist())\n",
    "\n",
    "    val_balance_acc = balanced_accuracy_score(val_pred, val_label)\n",
    "    val_avg_loss = val_cum_loss / len(dataloader_val)\n",
    "    print(\n",
    "        f\"val_balance_acc : {np.round(val_balance_acc, 6)} / val_avg_loss : {np.round(val_avg_loss, 6)}\"\n",
    "    )\n",
    "\n",
    "    if val_balance_acc > best_accuracy:\n",
    "        best_accuracy = val_balance_acc\n",
    "        print(\"Improve avg accuracy :\")\n",
    "\n",
    "        save_path = os.path.join(\"./\", \"model\" + str(epoch) + \".pt\")\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"scheduler_state_dict\": scheduler.state_dict()\n",
    "                if cfg[\"scheduler\"] is not None\n",
    "                else None,\n",
    "            },\n",
    "            save_path,\n",
    "        )\n",
    "        print(\"checkpoint saved to: {}\".format(save_path))\n",
    "\n",
    "    if not cfg[\"no_wandb\"]:\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"balance_acc/train\": train_balance_acc,\n",
    "                \"loss/train\": train_avg_loss,\n",
    "                \"balance_acc/val\": val_balance_acc,\n",
    "                \"loss/val\": val_avg_loss,\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "if not cfg[\"no_wandb\"]:\n",
    "    model_artifact = wandb.Artifact(\n",
    "        \"model\" + str(uuid.uuid1()).replace(\"-\", \"\"), type=\"model\"\n",
    "    )\n",
    "    model_artifact.add_file(save_path)\n",
    "    wandb.log_artifact(model_artifact)\n",
    "\n",
    "    description_artifact = wandb.Artifact(\n",
    "        \"description_model\" + str(uuid.uuid1()).replace(\"-\", \"\"), type=\"python\"\n",
    "    )\n",
    "\n",
    "    description_artifact.add_file(\"/kaggle/working/dlmi/src/model.py\")\n",
    "    description_artifact.add_file(\"/kaggle/working/dlmi/src/utils.py\")\n",
    "    description_artifact.add_file(\"/kaggle/working/dlmi/src/data.py\")\n",
    "    wandb.log_artifact(description_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T12:00:58.391336Z",
     "iopub.status.busy": "2024-03-27T12:00:58.391053Z",
     "iopub.status.idle": "2024-03-27T12:00:59.357139Z",
     "shell.execute_reply": "2024-03-27T12:00:59.356102Z",
     "shell.execute_reply.started": "2024-03-27T12:00:58.391310Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataloader_test = data_factory(\n",
    "    cfg,\n",
    "    mode=\"test\",\n",
    "    split_indexes=test_index,\n",
    "    path_root=path_root,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    transform=transform_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T12:00:59.358695Z",
     "iopub.status.busy": "2024-03-27T12:00:59.358370Z",
     "iopub.status.idle": "2024-03-27T12:01:26.287091Z",
     "shell.execute_reply": "2024-03-27T12:01:26.286146Z",
     "shell.execute_reply.started": "2024-03-27T12:00:59.358670Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:26<00:00,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file '/kaggle/working/submission_pretrain.csv' has been created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "list_prediction = []\n",
    "list_id = []\n",
    "for batch in tqdm(dataloader_test):\n",
    "    x, annotation = batch\n",
    "    with torch.no_grad():\n",
    "        x = model(x.to(cfg[\"device_1\"]))\n",
    "    pred = torch.argmax(soft_max(x), dim=1)\n",
    "    list_prediction.extend(pred.tolist())\n",
    "    list_id.extend(annotation[\"ID\"])\n",
    "\n",
    "    # Create a DataFrame from the lists\n",
    "df = pd.DataFrame({\"Id\": list_id, \"Predicted\": list_prediction})\n",
    "\n",
    "\n",
    "grouped_counts = df.groupby(\"Id\")[\"Predicted\"].value_counts().unstack(fill_value=0)\n",
    "df_grouped = grouped_counts.apply(np.argmax, axis=1)\n",
    "df_grouped = pd.DataFrame({\"Id\": df_grouped.index, \"Predicted\": df_grouped.values})\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "df_grouped.to_csv(cfg[\"filename\"], index=False)\n",
    "\n",
    "print(f\"CSV file '{cfg['filename']}' has been created successfully.\")\n",
    "\n",
    "if not cfg[\"no_wandb\"]:\n",
    "    submission_artifact = wandb.Artifact(\n",
    "        \"submission\" + str(uuid.uuid1()).replace(\"-\", \"\"), type=\"csv\"\n",
    "    )\n",
    "    submission_artifact.add_file(cfg[\"filename\"])\n",
    "    wandb.log_artifact(submission_artifact)\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create config.\n",
    "\n",
    "This config contains all the hyparameter usefull for our experiments. There will be logged in wandb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weight for the MAE pretraining are avalaible and need to be download here : \n",
    "\n",
    "Drive with the weigth [here](https://drive.google.com/drive/u/0/folders/13yrd36hwnCahIzXtedJdakCQZdADHxLd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T12:01:26.288770Z",
     "iopub.status.busy": "2024-03-27T12:01:26.288417Z",
     "iopub.status.idle": "2024-03-27T12:01:26.297557Z",
     "shell.execute_reply": "2024-03-27T12:01:26.296570Z",
     "shell.execute_reply.started": "2024-03-27T12:01:26.288745Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"who\": \"baptiste\",  # or steven\n",
    "    \"no_wandb\": False,\n",
    "    \"name_exp\": f\"exmaple -traning\",\n",
    "    \"lr\": 1e-5,\n",
    "    \"batch_size\": 1,\n",
    "    \"nb_epochs\": 20,\n",
    "    \"timm\": True,  # is the model from timm\n",
    "    \"timm_model\": cfg[\"timm_model\"],\n",
    "    \"dino\": False,\n",
    "    \"dino_size\": \"vits\",  # vits, vitb, vitl, vitg\n",
    "    \"adapter\": \"lora\",  # bottleneck, adaptformer, lora, prompttuning\n",
    "    \"model_name\": \"PatientModelCrossAttentionTab\",  # 'vit_small_patch16_224.augreg_in21k', #timm based model\n",
    "    \"pretrained\": True,\n",
    "    \"pretrained_path\": save_path,\n",
    "    \"nb_class\": 2,\n",
    "    \"scheduler\": None,  # could be empty or linear, expo ...\n",
    "    \"dataset_name\": \"DatasetPerPatient\",\n",
    "    \"device_1\": \"cuda:0\",\n",
    "    \"device_2\": \"cuda:1\",  # for double device\n",
    "    # data augmentation\n",
    "    \"filename\": f\"{path_working}/submission_pretrain.csv\",\n",
    "    \"filename_finetune\": f\"{path_working}/submission_finetune.csv\",\n",
    "    \"sub_batch_size\": 16,\n",
    "    \"latent_att\": 512,\n",
    "    \"head_1\": 8,  # 4\n",
    "    \"head_2\": 2,\n",
    "    \"feature_dim\": cfg[\"feature_dim\"],  # DINOv2, VIT: 192 - 384\n",
    "    \"aggregation\": \"avg\",  # sum, avg, max\n",
    "    \"beta_1\": 0.5,\n",
    "    \"beta_2\": 0.9,\n",
    "    \"weight_decay\": 5e-2,\n",
    "    \"weight_class_0\": 3.0,\n",
    "    \"weight_class_1\": 1.0,\n",
    "    \"mask_ratio\": 0.75,\n",
    "    \"image_size\": 224,\n",
    "    \"patch_size\": 16,\n",
    "    \"mae_pretrained\": \"\",\n",
    "    \"with_tab\": True,\n",
    "    \"mode_split\": \"load\",  # load, strat\n",
    "    \"degrees\": (-5, 5),\n",
    "    \"translate\": (0.1, 0.1),\n",
    "    \"scale\": (1.0, 1.1),\n",
    "    \"fill\": (255, 232, 201),\n",
    "    \"p\": 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T12:01:26.299012Z",
     "iopub.status.busy": "2024-03-27T12:01:26.298736Z",
     "iopub.status.idle": "2024-03-27T12:01:26.316117Z",
     "shell.execute_reply": "2024-03-27T12:01:26.315275Z",
     "shell.execute_reply.started": "2024-03-27T12:01:26.298988Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# transform\n",
    "transform_train = T.Compose(\n",
    "    [\n",
    "        v2.PILToTensor(),\n",
    "        v2.RandomHorizontalFlip(p=cfg[\"p\"]),\n",
    "        v2.RandomVerticalFlip(p=cfg[\"p\"]),\n",
    "        v2.RandomAffine(\n",
    "            degrees=cfg[\"degrees\"],\n",
    "            translate=cfg[\"translate\"],\n",
    "            scale=cfg[\"scale\"],\n",
    "            fill=cfg[\"fill\"],\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_val = T.Compose(\n",
    "    [\n",
    "        v2.PILToTensor(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T12:01:26.317293Z",
     "iopub.status.busy": "2024-03-27T12:01:26.317048Z",
     "iopub.status.idle": "2024-03-27T12:01:27.360272Z",
     "shell.execute_reply": "2024-03-27T12:01:27.359336Z",
     "shell.execute_reply.started": "2024-03-27T12:01:26.317271Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The configuration is:\n",
      "who : baptiste\n",
      "no_wandb : False\n",
      "name_exp : exmaple -traning\n",
      "lr : 1e-05\n",
      "batch_size : 1\n",
      "nb_epochs : 20\n",
      "timm : True\n",
      "timm_model : vit_small_patch16_224.augreg_in21k\n",
      "dino : False\n",
      "dino_size : vits\n",
      "adapter : lora\n",
      "model_name : PatientModelCrossAttentionTab\n",
      "pretrained : True\n",
      "pretrained_path : ./model4.pt\n",
      "nb_class : 2\n",
      "scheduler : None\n",
      "dataset_name : DatasetPerPatient\n",
      "device_1 : cuda:0\n",
      "device_2 : cuda:1\n",
      "filename : /kaggle/working/submission_pretrain.csv\n",
      "filename_finetune : /kaggle/working/submission_finetune.csv\n",
      "sub_batch_size : 16\n",
      "latent_att : 512\n",
      "head_1 : 8\n",
      "head_2 : 2\n",
      "feature_dim : 384\n",
      "aggregation : avg\n",
      "beta_1 : 0.5\n",
      "beta_2 : 0.9\n",
      "weight_decay : 0.05\n",
      "weight_class_0 : 3.0\n",
      "weight_class_1 : 1.0\n",
      "mask_ratio : 0.75\n",
      "image_size : 224\n",
      "patch_size : 16\n",
      "mae_pretrained : \n",
      "with_tab : True\n",
      "mode_split : load\n",
      "degrees : (-5, 5)\n",
      "translate : (0.1, 0.1)\n",
      "scale : (1.0, 1.1)\n",
      "fill : (255, 232, 201)\n",
      "p : 0.1\n",
      "Loading custom model PatientModelCrossAttentionTab\n",
      "We load the weigths ./model4.pt\n",
      "Use lora adapter\n",
      "==================================================\n",
      "The model has 23505374 parameters\n",
      "The model has 1839710 trainable parameters\n",
      "It represents 7.827 % trainable parameters\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "\n",
    "# load data\n",
    "data_factory = DataloaderFactory()\n",
    "model_factory = ModelFactory()\n",
    "dataloader_train = data_factory(\n",
    "    cfg,\n",
    "    mode=\"train\",\n",
    "    split_indexes=train_index,\n",
    "    path_root=path_root,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    transform=transform_train,\n",
    "    oversampling={\"0\": 1, \"1\": 1},\n",
    ")\n",
    "\n",
    "dataloader_val = data_factory(\n",
    "    cfg,\n",
    "    mode=\"train\",\n",
    "    split_indexes=val_index,\n",
    "    path_root=path_root,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    transform=transform_val,\n",
    "    oversampling={\"0\": 1, \"1\": 1},\n",
    ")\n",
    "\n",
    "\n",
    "# load model\n",
    "model = model_factory(cfg).to(cfg[\"device_1\"])\n",
    "\n",
    "# optimizer and scheduler\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=cfg[\"lr\"],\n",
    "    betas=(cfg[\"beta_1\"], cfg[\"beta_2\"]),\n",
    "    weight_decay=cfg[\"weight_decay\"],\n",
    ")\n",
    "\n",
    "num_training_steps = cfg[\"nb_epochs\"] * len(dataloader_train)\n",
    "schedulerr = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=cfg[\"nb_epochs\"], eta_min=5e-6\n",
    ")\n",
    "# weight = torch.tensor([cfg['weight_class_0'], cfg['weight_class_1']]).to(cfg['device_1'])\n",
    "# loss_fn = torch.nn.CrossEntropyLoss(weight=weight)\n",
    "\n",
    "soft_max = torch.nn.Softmax(1)\n",
    "\n",
    "\n",
    "cfg[\"nb_params_train\"] = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "cfg[\"nb_params_tot\"] = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f'The model has {cfg[\"nb_params_tot\"]} parameters')\n",
    "print(f'The model has {cfg[\"nb_params_train\"]} trainable parameters')\n",
    "print(\n",
    "    f'It represents {np.round(100 * cfg[\"nb_params_train\"]/cfg[\"nb_params_tot\"], 3)} % trainable parameters'\n",
    ")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T12:01:27.361698Z",
     "iopub.status.busy": "2024-03-27T12:01:27.361418Z",
     "iopub.status.idle": "2024-03-27T12:01:27.366850Z",
     "shell.execute_reply": "2024-03-27T12:01:27.365794Z",
     "shell.execute_reply.started": "2024-03-27T12:01:27.361673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "weight = torch.tensor([2.5, 1.0]).to(\"cuda:0\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T12:01:27.368782Z",
     "iopub.status.busy": "2024-03-27T12:01:27.368437Z",
     "iopub.status.idle": "2024-03-27T12:35:14.895877Z",
     "shell.execute_reply": "2024-03-27T12:35:14.894460Z",
     "shell.execute_reply.started": "2024-03-27T12:01:27.368753Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbaptcallard\u001b[0m (\u001b[33mii_timm\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20240327_120129-9dqzfe31</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ii_timm/DLMI/runs/9dqzfe31' target=\"_blank\">exmaple -traning</a></strong> to <a href='https://wandb.ai/ii_timm/DLMI' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ii_timm/DLMI' target=\"_blank\">https://wandb.ai/ii_timm/DLMI</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ii_timm/DLMI/runs/9dqzfe31' target=\"_blank\">https://wandb.ai/ii_timm/DLMI/runs/9dqzfe31</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training ...\n",
      "==================================================\n",
      "                Epoch 0\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [01:30<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.565359 / train_balance_acc_ml : 0.965116 / train_avg_loss : 0.181272\n",
      "Count [0 1] [85 45]\n",
      "Count_ml [0 1] [43 87]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:11<00:00,  2.84it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.69697 / val_balance_acc_ml : 0.925926 / val_avg_loss : 0.160286\n",
      "Count [1] [33]\n",
      "Count_ml [0 1] [ 6 27]\n",
      "0.1602855297652158 10000\n",
      "Improve avg loss :\n",
      "checkpoint saved to: ./model0_finetune.pt\n",
      "time 0.6251700026857341\n",
      "==================================================\n",
      "                Epoch 1\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [01:27<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.643475 / train_balance_acc_ml : 0.983871 / train_avg_loss : 0.170072\n",
      "Count [0 1] [ 24 106]\n",
      "Count_ml [0 1] [37 93]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:11<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.910714 / val_balance_acc_ml : 0.96 / val_avg_loss : 0.136785\n",
      "Count [0 1] [ 5 28]\n",
      "Count_ml [0 1] [ 8 25]\n",
      "0.13678534182183671 0.1602855297652158\n",
      "Improve avg loss :\n",
      "checkpoint saved to: ./model1_finetune.pt\n",
      "time 0.6121859345699381\n",
      "==================================================\n",
      "                Epoch 2\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [01:26<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.756235 / train_balance_acc_ml : 0.873611 / train_avg_loss : 0.14586\n",
      "Count [0 1] [41 89]\n",
      "Count_ml [0 1] [40 90]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:11<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.738095 / val_balance_acc_ml : 0.794118 / val_avg_loss : 0.146761\n",
      "Count [0 1] [21 12]\n",
      "Count_ml [0 1] [17 16]\n",
      "0.14676117961944052 0.13678534182183671\n",
      "time 0.6067339203840384\n",
      "==================================================\n",
      "                Epoch 3\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [01:27<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.870532 / train_balance_acc_ml : 0.896167 / train_avg_loss : 0.116524\n",
      "Count [0 1] [37 93]\n",
      "Count_ml [0 1] [38 92]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:11<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.916667 / val_balance_acc_ml : 0.916667 / val_avg_loss : 0.064108\n",
      "Count [0 1] [12 21]\n",
      "Count_ml [0 1] [12 21]\n",
      "0.0641081325681598 0.13678534182183671\n",
      "Improve avg loss :\n",
      "checkpoint saved to: ./model3_finetune.pt\n",
      "time 0.6094950079186562\n",
      "==================================================\n",
      "                Epoch 4\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [01:28<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.800325 / train_balance_acc_ml : 0.853084 / train_avg_loss : 0.106288\n",
      "Count [0 1] [42 88]\n",
      "Count_ml [0 1] [42 88]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:12<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.8125 / val_balance_acc_ml : 0.857143 / val_avg_loss : 0.109998\n",
      "Count [0 1] [16 17]\n",
      "Count_ml [0 1] [14 19]\n",
      "0.10999823945828459 0.0641081325681598\n",
      "time 0.6165041382327402\n",
      "==================================================\n",
      "                Epoch 5\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [01:27<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.880926 / train_balance_acc_ml : 0.912991 / train_avg_loss : 0.099894\n",
      "Count [0 1] [41 89]\n",
      "Count_ml [0 1] [43 87]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:11<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.857143 / val_balance_acc_ml : 0.857143 / val_avg_loss : 0.091142\n",
      "Count [0 1] [14 19]\n",
      "Count_ml [0 1] [14 19]\n",
      "0.09114168782252818 0.0641081325681598\n",
      "time 0.6103764823609334\n",
      "==================================================\n",
      "                Epoch 6\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [01:27<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.898739 / train_balance_acc_ml : 0.912991 / train_avg_loss : 0.0821\n",
      "Count [0 1] [41 89]\n",
      "Count_ml [0 1] [43 87]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:11<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.884615 / val_balance_acc_ml : 0.884615 / val_avg_loss : 0.07291\n",
      "Count [0 1] [13 20]\n",
      "Count_ml [0 1] [13 20]\n",
      "0.07291047138542953 0.0641081325681598\n",
      "time 0.6065890467240035\n",
      "==================================================\n",
      "                Epoch 7\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [01:27<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.891667 / train_balance_acc_ml : 0.93956 / train_avg_loss : 0.079376\n",
      "Count [0 1] [40 90]\n",
      "Count_ml [0 1] [39 91]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:12<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.884615 / val_balance_acc_ml : 0.916667 / val_avg_loss : 0.068481\n",
      "Count [0 1] [13 20]\n",
      "Count_ml [0 1] [12 21]\n",
      "0.06848126766315986 0.0641081325681598\n",
      "time 0.6122734502780657\n",
      "==================================================\n",
      "                Epoch 8\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [01:27<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.921245 / train_balance_acc_ml : 0.927778 / train_avg_loss : 0.054952\n",
      "Count [0 1] [39 91]\n",
      "Count_ml [0 1] [40 90]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:11<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.794118 / val_balance_acc_ml : 0.8125 / val_avg_loss : 0.203237\n",
      "Count [0 1] [17 16]\n",
      "Count_ml [0 1] [16 17]\n",
      "0.20323678261995543 0.0641081325681598\n",
      "time 0.6123736387381524\n",
      "==================================================\n",
      "                Epoch 9\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [01:27<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.927778 / train_balance_acc_ml : 0.945833 / train_avg_loss : 0.044545\n",
      "Count [0 1] [40 90]\n",
      "Count_ml [0 1] [40 90]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:11<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.857143 / val_balance_acc_ml : 0.857143 / val_avg_loss : 0.119003\n",
      "Count [0 1] [14 19]\n",
      "Count_ml [0 1] [14 19]\n",
      "0.11900278705698755 0.0641081325681598\n",
      "time 0.6101426844216563\n",
      "==================================================\n",
      "                Epoch 10\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [01:27<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.952179 / train_balance_acc_ml : 0.963889 / train_avg_loss : 0.043781\n",
      "Count [0 1] [41 89]\n",
      "Count_ml [0 1] [40 90]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:11<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.857143 / val_balance_acc_ml : 0.857143 / val_avg_loss : 0.108016\n",
      "Count [0 1] [14 19]\n",
      "Count_ml [0 1] [14 19]\n",
      "0.10801649957394341 0.0641081325681598\n",
      "time 0.6129209761239268\n",
      "==================================================\n",
      "                Epoch 11\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [01:26<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.963889 / train_balance_acc_ml : 0.963889 / train_avg_loss : 0.040862\n",
      "Count [0 1] [40 90]\n",
      "Count_ml [0 1] [40 90]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:12<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.857143 / val_balance_acc_ml : 0.857143 / val_avg_loss : 0.088678\n",
      "Count [0 1] [14 19]\n",
      "Count_ml [0 1] [14 19]\n",
      "0.08867768473503405 0.0641081325681598\n",
      "time 0.6043388755774937\n",
      "==================================================\n",
      "                Epoch 12\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [01:28<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.905844 / train_balance_acc_ml : 0.905844 / train_avg_loss : 0.065654\n",
      "Count [0 1] [42 88]\n",
      "Count_ml [0 1] [42 88]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:11<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.954545 / val_balance_acc_ml : 0.954545 / val_avg_loss : 0.049132\n",
      "Count [0 1] [11 22]\n",
      "Count_ml [0 1] [11 22]\n",
      "0.04913204532666979 0.0641081325681598\n",
      "Improve avg loss :\n",
      "checkpoint saved to: ./model12_finetune.pt\n",
      "time 0.619249358498977\n",
      "==================================================\n",
      "                Epoch 13\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [01:27<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.963889 / train_balance_acc_ml : 0.981944 / train_avg_loss : 0.029378\n",
      "Count [0 1] [40 90]\n",
      "Count_ml [0 1] [40 90]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:11<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.857143 / val_balance_acc_ml : 0.857143 / val_avg_loss : 0.138232\n",
      "Count [0 1] [14 19]\n",
      "Count_ml [0 1] [14 19]\n",
      "0.13823183694006674 0.04913204532666979\n",
      "time 0.6058681084334485\n",
      "==================================================\n",
      "                Epoch 14\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [01:27<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.947741 / train_balance_acc_ml : 0.947741 / train_avg_loss : 0.037326\n",
      "Count [0 1] [43 87]\n",
      "Count_ml [0 1] [43 87]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:11<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.857143 / val_balance_acc_ml : 0.884615 / val_avg_loss : 0.08347\n",
      "Count [0 1] [14 19]\n",
      "Count_ml [0 1] [13 20]\n",
      "0.08347021699121411 0.04913204532666979\n",
      "time 0.6083543271374848\n",
      "==================================================\n",
      "                Epoch 15\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [01:27<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.930366 / train_balance_acc_ml : 0.941017 / train_avg_loss : 0.068677\n",
      "Count [0 1] [43 87]\n",
      "Count_ml [0 1] [42 88]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:11<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.857143 / val_balance_acc_ml : 0.857143 / val_avg_loss : 0.116876\n",
      "Count [0 1] [14 19]\n",
      "Count_ml [0 1] [14 19]\n",
      "0.11687600659562039 0.04913204532666979\n",
      "time 0.6069642049403279\n",
      "==================================================\n",
      "                Epoch 16\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [01:26<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.981944 / train_balance_acc_ml : 0.981944 / train_avg_loss : 0.019099\n",
      "Count [0 1] [40 90]\n",
      "Count_ml [0 1] [40 90]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:12<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.8125 / val_balance_acc_ml : 0.8125 / val_avg_loss : 0.204303\n",
      "Count [0 1] [16 17]\n",
      "Count_ml [0 1] [16 17]\n",
      "0.20430327898297532 0.04913204532666979\n",
      "time 0.6070266311154043\n",
      "==================================================\n",
      "                Epoch 17\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [01:28<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.952179 / train_balance_acc_ml : 0.958604 / train_avg_loss : 0.049862\n",
      "Count [0 1] [41 89]\n",
      "Count_ml [0 1] [42 88]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:11<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.857143 / val_balance_acc_ml : 0.857143 / val_avg_loss : 0.140232\n",
      "Count [0 1] [14 19]\n",
      "Count_ml [0 1] [14 19]\n",
      "0.14023184849208697 0.04913204532666979\n",
      "time 0.6139632631664628\n",
      "==================================================\n",
      "                Epoch 18\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [01:28<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.969992 / train_balance_acc_ml : 0.969992 / train_avg_loss : 0.027799\n",
      "Count [0 1] [41 89]\n",
      "Count_ml [0 1] [41 89]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:11<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.821154 / val_balance_acc_ml : 0.857143 / val_avg_loss : 0.118872\n",
      "Count [0 1] [13 20]\n",
      "Count_ml [0 1] [14 19]\n",
      "0.11887182341091705 0.04913204532666979\n",
      "time 0.6144075583826545\n",
      "==================================================\n",
      "                Epoch 19\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [01:28<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_balance_acc : 0.981944 / train_balance_acc_ml : 0.981944 / train_avg_loss : 0.020556\n",
      "Count [0 1] [40 90]\n",
      "Count_ml [0 1] [40 90]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:11<00:00,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_balance_acc : 0.821154 / val_balance_acc_ml : 0.857143 / val_avg_loss : 0.164337\n",
      "Count [0 1] [13 20]\n",
      "Count_ml [0 1] [14 19]\n",
      "0.16433718178858603 0.04913204532666979\n",
      "time 0.6135741889111104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "###              Training\n",
    "#############################################\n",
    "\n",
    "best_loss = 10000\n",
    "\n",
    "if not cfg[\"no_wandb\"]:\n",
    "    run = wandb.init(\n",
    "        project=\"DLMI\",\n",
    "        entity=\"ii_timm\",\n",
    "        name=cfg[\"name_exp\"],\n",
    "        config=cfg,\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Start Training ...\")\n",
    "for epoch in range(cfg[\"nb_epochs\"]):\n",
    "    model.train()\n",
    "    print(\"=\" * 50)\n",
    "    print(\" \" * 15, f\"Epoch {epoch}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    train_cum_loss = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    #############################\n",
    "    ###     VAL loop\n",
    "    #############################\n",
    "    train_pred = []\n",
    "    train_label = []\n",
    "    train_pred_ml = []\n",
    "\n",
    "    for x, annotation in tqdm(dataloader_train):\n",
    "        optimizer.zero_grad()\n",
    "        x = x.to(cfg[\"device_1\"]).squeeze(0)\n",
    "\n",
    "        ## ML predictions\n",
    "        converted_dict = {\n",
    "            \"ID\": annotation[\"ID\"][0],  # Convert list to single value\n",
    "            \"LYMPH_COUNT\": annotation[\"LYMPH_COUNT\"].item(),  # Convert tensor to float\n",
    "            \"AGE\": annotation[\"AGE\"].item(),  # Convert tensor to float\n",
    "            \"BIN_GENDER\": int(annotation[\"BIN_GENDER\"].item()),  # Convert tensor to int\n",
    "            \"LABEL\": annotation[\n",
    "                \"LABEL\"\n",
    "            ].item(),  # Convert tensor to int (assuming LABEL should also be an int)\n",
    "        }\n",
    "\n",
    "        ## DL predictions\n",
    "        features = [\n",
    "            converted_dict[\"LYMPH_COUNT\"],\n",
    "            converted_dict[\"AGE\"],\n",
    "            converted_dict[\"BIN_GENDER\"],\n",
    "        ]\n",
    "        features_for_prediction = [features]\n",
    "        prediction = best_clf.predict_proba(features_for_prediction)\n",
    "\n",
    "        if cfg[\"with_tab\"]:\n",
    "            # define tabular data\n",
    "            lymph_count, age, bin_gender = (\n",
    "                annotation[\"LYMPH_COUNT\"],\n",
    "                annotation[\"AGE\"],\n",
    "                annotation[\"BIN_GENDER\"],\n",
    "            )\n",
    "            x_tab = torch.zeros((1, 4)).to(cfg[\"device_1\"])\n",
    "            x_tab[0, int(bin_gender)] = 1\n",
    "            x_tab[0, 2] = torch.clamp(age + 1e-6 * np.random.rand(1)[0], 0, 1)\n",
    "            x_tab[0, 3] = torch.clamp(lymph_count + 1e-6 * np.random.rand(1)[0], 0, 1)\n",
    "\n",
    "            xout_sub_batch = model(x, x_tab, \"train\")\n",
    "        else:\n",
    "            # None tabular data\n",
    "            xout_sub_batch = model(x, \"train\")\n",
    "\n",
    "        # compute the loss and pred\n",
    "        loss = loss_fn(\n",
    "            xout_sub_batch.unsqueeze(0), annotation[\"LABEL\"].to(cfg[\"device_1\"])\n",
    "        ) / (x.shape[0] / cfg[\"sub_batch_size\"])\n",
    "        pred = torch.argmax(soft_max(xout_sub_batch.unsqueeze(0)), dim=1)\n",
    "        pred_ml = torch.argmax(\n",
    "            0.75 * soft_max(xout_sub_batch.unsqueeze(0)).detach().cpu()\n",
    "            + 0.25 * prediction,\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        train_cum_loss += loss.item()\n",
    "\n",
    "        # store the res.\n",
    "        train_pred.extend(pred.detach().cpu().tolist())\n",
    "        train_pred_ml.extend(pred_ml.detach().cpu().tolist())\n",
    "        train_label.extend(annotation[\"LABEL\"].detach().cpu().tolist())\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "    # compute agg. scores\n",
    "    train_balance_acc = balanced_accuracy_score(train_pred, train_label)\n",
    "    train_balance_acc_ml = balanced_accuracy_score(train_pred_ml, train_label)\n",
    "\n",
    "    train_avg_loss = train_cum_loss / len(dataloader_train)\n",
    "    print(\n",
    "        f\"train_balance_acc : {np.round(train_balance_acc, 6)} / train_balance_acc_ml : {np.round(train_balance_acc_ml, 6)} / train_avg_loss : {np.round(train_avg_loss, 6)}\"\n",
    "    )\n",
    "    unique_train, count_train = np.unique(train_pred, return_counts=True)\n",
    "    unique_train_ml, count_train_ml = np.unique(train_pred_ml, return_counts=True)\n",
    "    print(\"Count\", unique_train, count_train)\n",
    "    print(\"Count_ml\", unique_train_ml, count_train_ml)\n",
    "\n",
    "    # edge case\n",
    "    if len(unique_train) == 1:\n",
    "        if unique_train[0] == 1:\n",
    "            count_train = count_train.tolist()\n",
    "            count_train.insert(0, 0)\n",
    "        if unique_train[0] == 0:\n",
    "            count_train = count_train.tolist()\n",
    "            count_train.append(0)\n",
    "\n",
    "    #############################\n",
    "    ###     VAL loop\n",
    "    #############################\n",
    "    val_pred = []\n",
    "    val_label = []\n",
    "    val_pred_ml = []\n",
    "    val_cum_loss = 0\n",
    "    model.eval()\n",
    "    for x, annotation in tqdm(dataloader_val):\n",
    "        converted_dict = {\n",
    "            \"ID\": annotation[\"ID\"][0],  # Convert list to single value\n",
    "            \"LYMPH_COUNT\": annotation[\"LYMPH_COUNT\"].item(),  # Convert tensor to float\n",
    "            \"AGE\": annotation[\"AGE\"].item(),  # Convert tensor to float\n",
    "            \"BIN_GENDER\": int(annotation[\"BIN_GENDER\"].item()),  # Convert tensor to int\n",
    "            \"LABEL\": annotation[\n",
    "                \"LABEL\"\n",
    "            ].item(),  # Convert tensor to int (assuming LABEL should also be an int)\n",
    "        }\n",
    "\n",
    "        ## Pred ML\n",
    "\n",
    "        features = [\n",
    "            converted_dict[\"LYMPH_COUNT\"],\n",
    "            converted_dict[\"AGE\"],\n",
    "            converted_dict[\"BIN_GENDER\"],\n",
    "        ]\n",
    "        features_for_prediction = [features]\n",
    "        prediction = best_clf.predict_proba(features_for_prediction)\n",
    "\n",
    "        # Pred DL\n",
    "\n",
    "        x = x.to(cfg[\"device_1\"]).squeeze(0)\n",
    "\n",
    "        if cfg[\"with_tab\"]:\n",
    "            # define tabular data\n",
    "            lymph_count, age, bin_gender = (\n",
    "                annotation[\"LYMPH_COUNT\"],\n",
    "                annotation[\"AGE\"],\n",
    "                annotation[\"BIN_GENDER\"],\n",
    "            )\n",
    "            x_tab = torch.zeros((1, 4)).to(cfg[\"device_1\"])\n",
    "            x_tab[0, int(bin_gender)] = 1\n",
    "            x_tab[0, 2] = age\n",
    "            x_tab[0, 3] = lymph_count\n",
    "\n",
    "            xout_sub_batch = model(x, x_tab, \"val\")\n",
    "        else:\n",
    "            xout_sub_batch = model(x, \"val\")\n",
    "        # compute loss\n",
    "        loss = loss_fn(\n",
    "            xout_sub_batch.unsqueeze(0), annotation[\"LABEL\"].to(cfg[\"device_1\"])\n",
    "        ) / (x.shape[0] / cfg[\"sub_batch_size\"])\n",
    "        pred = torch.argmax(soft_max(xout_sub_batch.unsqueeze(0)), dim=1)\n",
    "        pred_ml = torch.argmax(\n",
    "            0.75 * soft_max(xout_sub_batch.unsqueeze(0)).detach().cpu()\n",
    "            + 0.25 * prediction,\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        val_cum_loss += loss.item()\n",
    "        val_pred.extend(pred.detach().cpu().tolist())\n",
    "        val_pred_ml.extend(pred_ml.detach().cpu().tolist())\n",
    "        val_label.extend(annotation[\"LABEL\"].detach().cpu().tolist())\n",
    "\n",
    "    # compute agg. scores\n",
    "    val_balance_acc = balanced_accuracy_score(val_pred, val_label)\n",
    "    val_balance_acc_ml = balanced_accuracy_score(val_pred_ml, val_label)\n",
    "    val_avg_loss = val_cum_loss / len(dataloader_val)\n",
    "    print(\n",
    "        f\"val_balance_acc : {np.round(val_balance_acc, 6)} / val_balance_acc_ml : {np.round(val_balance_acc_ml, 6)} / val_avg_loss : {np.round(val_avg_loss, 6)}\"\n",
    "    )\n",
    "\n",
    "    unique_val, count_val = np.unique(val_pred, return_counts=True)\n",
    "    unique_val_ml, count_val_ml = np.unique(val_pred_ml, return_counts=True)\n",
    "    print(\"Count\", unique_val, count_val)\n",
    "    print(\"Count_ml\", unique_val_ml, count_val_ml)\n",
    "\n",
    "    # edge case\n",
    "    if len(unique_val) == 1:\n",
    "        if unique_val[0] == 1:\n",
    "            count_val = count_val.tolist()\n",
    "            count_val.insert(0, 0)\n",
    "        if unique_val[0] == 0:\n",
    "            count_val = count_val.tolist()\n",
    "            count_val.append(0)\n",
    "    print(val_avg_loss, best_loss)\n",
    "\n",
    "    # Save best model + prints\n",
    "    if val_avg_loss < best_loss:\n",
    "        best_loss = val_avg_loss\n",
    "\n",
    "        print(\"Improve avg loss :\")\n",
    "        save_path_finetune = os.path.join(\"./\", \"model\" + str(epoch) + \"_finetune.pt\")\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"scheduler_state_dict\": scheduler.state_dict()\n",
    "                if cfg[\"scheduler\"] is not None\n",
    "                else None,\n",
    "            },\n",
    "            save_path_finetune,\n",
    "        )\n",
    "        print(\"checkpoint saved to: {}\".format(save_path_finetune))\n",
    "\n",
    "    print(\n",
    "        \"time\",\n",
    "        (time.time() - start_time) / (len(dataloader_val) + len(dataloader_train)),\n",
    "    )\n",
    "\n",
    "    # Save in Wandb\n",
    "    if not cfg[\"no_wandb\"]:\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"balance_acc/train\": train_balance_acc,\n",
    "                \"balance_acc_ml/train\": train_balance_acc_ml,\n",
    "                \"loss/train\": train_avg_loss,\n",
    "                \"balance_acc/val\": val_balance_acc,\n",
    "                \"balance_acc_ml/val\": val_balance_acc_ml,\n",
    "                \"loss/val\": val_avg_loss,\n",
    "                \"time\": (time.time() - start_time)\n",
    "                / (len(dataloader_val) + len(dataloader_train)),\n",
    "                \"count_train_0\": count_train[0],\n",
    "                \"count_train_1\": count_train[1],\n",
    "                \"count_val_0\": count_val[0],\n",
    "                \"count_val_1\": count_val[1],\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T12:35:14.899309Z",
     "iopub.status.busy": "2024-03-27T12:35:14.897626Z",
     "iopub.status.idle": "2024-03-27T12:35:16.797516Z",
     "shell.execute_reply": "2024-03-27T12:35:16.794007Z",
     "shell.execute_reply.started": "2024-03-27T12:35:14.899264Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if not cfg[\"no_wandb\"]:\n",
    "    model_artifact = wandb.Artifact(\n",
    "        \"model\" + str(uuid.uuid1()).replace(\"-\", \"\"), type=\"model\"\n",
    "    )\n",
    "    model_artifact.add_file(save_path_finetune)\n",
    "    wandb.log_artifact(model_artifact)\n",
    "\n",
    "    description_artifact = wandb.Artifact(\n",
    "        \"description_model\" + str(uuid.uuid1()).replace(\"-\", \"\"), type=\"python\"\n",
    "    )\n",
    "\n",
    "    !cp -r $path_working/dlmi/src/* $path_working/\n",
    "    description_artifact.add_file(f\"{path_working}/model.py\")\n",
    "    description_artifact.add_file(f\"{path_working}/utils.py\")\n",
    "    description_artifact.add_file(f\"{path_working}/data.py\")\n",
    "    wandb.log_artifact(description_artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T12:35:16.799704Z",
     "iopub.status.busy": "2024-03-27T12:35:16.799288Z",
     "iopub.status.idle": "2024-03-27T12:35:16.849773Z",
     "shell.execute_reply": "2024-03-27T12:35:16.848769Z",
     "shell.execute_reply.started": "2024-03-27T12:35:16.799662Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataloader_test = data_factory(\n",
    "    cfg,\n",
    "    mode=\"test\",\n",
    "    split_indexes=test_index,\n",
    "    path_root=path_root,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    transform=transform_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T12:35:16.851601Z",
     "iopub.status.busy": "2024-03-27T12:35:16.851211Z",
     "iopub.status.idle": "2024-03-27T12:35:33.704620Z",
     "shell.execute_reply": "2024-03-27T12:35:33.703407Z",
     "shell.execute_reply.started": "2024-03-27T12:35:16.851564Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model ./model12_finetune.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:16<00:00,  2.55it/s]\n"
     ]
    }
   ],
   "source": [
    "test_pred = []\n",
    "test_ID = []\n",
    "\n",
    "\n",
    "map_results = {\n",
    "    \"Id\": [],\n",
    "    \"Predicted\": [],\n",
    "}\n",
    "\n",
    "\n",
    "map_results_ml = {\n",
    "    \"Id\": [],\n",
    "    \"Predicted\": [],\n",
    "}\n",
    "\n",
    "\n",
    "map_results_logit = {\n",
    "    \"Id\": [],\n",
    "    \"logit_0\": [],\n",
    "    \"logit_1\": [],\n",
    "}\n",
    "\n",
    "print(\"Load model\", save_path_finetune)\n",
    "model.load_state_dict(torch.load(save_path_finetune)[\"model_state_dict\"])\n",
    "model.eval()\n",
    "for x, annotation in tqdm(dataloader_test):\n",
    "    # forward\n",
    "    converted_dict = {\n",
    "        \"ID\": annotation[\"ID\"][0],  # Convert list to single value\n",
    "        \"LYMPH_COUNT\": annotation[\"LYMPH_COUNT\"].item(),  # Convert tensor to float\n",
    "        \"AGE\": annotation[\"AGE\"].item(),  # Convert tensor to float\n",
    "        \"BIN_GENDER\": int(annotation[\"BIN_GENDER\"].item()),  # Convert tensor to int\n",
    "        \"LABEL\": annotation[\n",
    "            \"LABEL\"\n",
    "        ].item(),  # Convert tensor to int (assuming LABEL should also be an int)\n",
    "    }\n",
    "\n",
    "    features = [\n",
    "        converted_dict[\"LYMPH_COUNT\"],\n",
    "        converted_dict[\"AGE\"],\n",
    "        converted_dict[\"BIN_GENDER\"],\n",
    "    ]\n",
    "    features_for_prediction = [features]\n",
    "    prediction_ml = best_clf.predict_proba(features_for_prediction)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x = x.to(cfg[\"device_1\"]).squeeze(0)\n",
    "\n",
    "        if cfg[\"with_tab\"]:\n",
    "            # define tabular data\n",
    "            lymph_count, age, bin_gender = (\n",
    "                annotation[\"LYMPH_COUNT\"],\n",
    "                annotation[\"AGE\"],\n",
    "                annotation[\"BIN_GENDER\"],\n",
    "            )\n",
    "            x_tab = torch.zeros((1, 4)).to(cfg[\"device_1\"])\n",
    "            x_tab[0, int(bin_gender)] = 1\n",
    "            x_tab[0, 2] = age\n",
    "            x_tab[0, 3] = lymph_count\n",
    "\n",
    "            x = model(x, x_tab, \"val\")\n",
    "        else:\n",
    "            x = model(x, \"val\")\n",
    "\n",
    "        logit = soft_max(x.unsqueeze(0))\n",
    "        pred = torch.argmax(logit, dim=1)\n",
    "        pred_ml = torch.argmax(\n",
    "            0.85 * soft_max(x.unsqueeze(0)).detach().cpu() + 0.15 * prediction_ml, dim=1\n",
    "        )\n",
    "\n",
    "        # DL\n",
    "        map_results[\"Predicted\"].extend(pred.detach().cpu().tolist())\n",
    "        map_results[\"Id\"].extend(annotation[\"ID\"])\n",
    "\n",
    "        map_results_logit[\"logit_0\"].append(logit[0][0].item())\n",
    "        map_results_logit[\"logit_1\"].append(logit[0][1].item())\n",
    "        map_results_logit[\"Id\"].extend(annotation[\"ID\"])\n",
    "\n",
    "        # DL + ML\n",
    "        map_results_ml[\"Predicted\"].extend(pred_ml.detach().cpu().tolist())\n",
    "        map_results_ml[\"Id\"].extend(annotation[\"ID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save in Wandb !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T12:35:33.706705Z",
     "iopub.status.busy": "2024-03-27T12:35:33.706218Z",
     "iopub.status.idle": "2024-03-27T12:35:40.712280Z",
     "shell.execute_reply": "2024-03-27T12:35:40.711578Z",
     "shell.execute_reply.started": "2024-03-27T12:35:33.706666Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='103.869 MB of 103.869 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>balance_acc/train</td><td>▁▂▄▆▅▆▇▆▇▇▇█▇█▇▇█▇██</td></tr><tr><td>balance_acc/val</td><td>▁▇▂▇▄▅▆▆▄▅▅▅█▅▅▅▄▅▄▄</td></tr><tr><td>balance_acc_ml/train</td><td>▇█▂▃▁▄▄▆▅▆▇▇▄█▆▆█▇▇█</td></tr><tr><td>balance_acc_ml/val</td><td>▇█▁▆▄▄▅▆▂▄▄▄█▄▅▄▂▄▄▄</td></tr><tr><td>count_train_0</td><td>█▁▃▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>count_train_1</td><td>▁█▆▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>count_val_0</td><td>▁▃█▅▆▆▅▅▇▆▆▆▅▆▆▆▆▆▅▅</td></tr><tr><td>count_val_1</td><td>█▆▁▄▃▃▄▄▂▃▃▃▄▃▃▃▃▃▄▄</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss/train</td><td>██▆▅▅▄▄▄▃▂▂▂▃▁▂▃▁▂▁▁</td></tr><tr><td>loss/val</td><td>▆▅▅▂▄▃▂▂█▄▄▃▁▅▃▄█▅▄▆</td></tr><tr><td>time</td><td>█▄▂▃▅▃▂▄▄▃▄▁▆▂▂▂▂▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>balance_acc/train</td><td>0.98194</td></tr><tr><td>balance_acc/val</td><td>0.82115</td></tr><tr><td>balance_acc_ml/train</td><td>0.98194</td></tr><tr><td>balance_acc_ml/val</td><td>0.85714</td></tr><tr><td>count_train_0</td><td>40</td></tr><tr><td>count_train_1</td><td>90</td></tr><tr><td>count_val_0</td><td>13</td></tr><tr><td>count_val_1</td><td>20</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>loss/train</td><td>0.02056</td></tr><tr><td>loss/val</td><td>0.16434</td></tr><tr><td>time</td><td>0.61358</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">exmaple -traning</strong> at: <a href='https://wandb.ai/ii_timm/DLMI/runs/9dqzfe31' target=\"_blank\">https://wandb.ai/ii_timm/DLMI/runs/9dqzfe31</a><br/>Synced 6 W&B file(s), 0 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240327_120129-9dqzfe31/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(map_results)\n",
    "df_results.to_csv(cfg[\"filename_finetune\"], index=False)\n",
    "\n",
    "df_results_ml = pd.DataFrame(map_results_ml)\n",
    "df_results_ml.to_csv(\"submission_dl_ml.csv\", index=False)\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame(map_results_logit)\n",
    "df_results.to_csv(\"logit.csv\", index=False)\n",
    "\n",
    "if not cfg[\"no_wandb\"]:\n",
    "    # log index\n",
    "    df_train_index = pd.DataFrame({\"train\": train_index})\n",
    "    df_train_index.to_csv(\"train_index.csv\", index=False)\n",
    "    df_val_index = pd.DataFrame({\"val\": val_index})\n",
    "    df_val_index.to_csv(\"val_index.csv\", index=False)\n",
    "\n",
    "    csv_artifact = wandb.Artifact(\n",
    "        \"submission\" + str(uuid.uuid1()).replace(\"-\", \"\"), type=\"csv\"\n",
    "    )\n",
    "    csv_artifact.add_file(cfg[\"filename_finetune\"])\n",
    "    csv_artifact.add_file(\"submission_dl_ml.csv\")\n",
    "    csv_artifact.add_file(cfg[\"filename\"])\n",
    "    csv_artifact.add_file(\"logit.csv\")\n",
    "    csv_artifact.add_file(\"train_index.csv\")\n",
    "    csv_artifact.add_file(\"val_index.csv\")\n",
    "    wandb.log_artifact(csv_artifact)\n",
    "\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4453724,
     "sourceId": 7641601,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4663257,
     "sourceId": 7933186,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
